{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patch_gnn.graph import extract_neighborhood, generate_feature_dataframe\n",
    "from pyprojroot import here\n",
    "from proteingraph import read_pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, I will demo how to use the functions provided in `patch_gnn` and other packages\n",
    "to do graph neural network training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in example data\n",
    "\n",
    "This is an example dataset, an HIV Protease, from the PDB.\n",
    "\n",
    "Firstly, we use `proteingraph.read_pdb` to get back a Graph object.\n",
    "\n",
    "_Note: This should later be delegated to `graphein`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_graph = read_pdb(here() / \"data/hiv1_homology_model.pdb\")\n",
    "hiv_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly inspect what nodes are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_graph.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate all patches from a graph of radius size 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patch_gnn.graph import generate_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_patches = generate_patches(hiv_graph, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize a few of them, let's look at how they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nx.draw(graph_patches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(graph_patches[-10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the node input data\n",
    "\n",
    "We are going to now generate the node feature matrices for each of the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_feats = pd.read_csv(here() / \"data/amino_acid_properties.csv\", index_col=0)\n",
    "aa_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_amino_acid(n, d, aa_feats: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Featurize a single amino acid.\n",
    "    \n",
    "    :param n: Graph node.\n",
    "    :param d: Graph node attributes.\n",
    "    :param aa_feats: Dataframe containing amino acid features.\n",
    "    \"\"\"\n",
    "    aa = d[\"residue_name\"]\n",
    "    feats = pd.Series(aa_feats[aa], name=n)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, collect the node featurization functions into a list.\n",
    "We must use `partial` to enure that each function's signature is limited to `n, d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "feature_funcs = [partial(featurize_amino_acid, aa_feats=aa_feats)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we stack the feature tensors for all graphs together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patch_gnn.graph import stack_feature_tensors\n",
    "Fs = stack_feature_tensors(graph_patches, funcs=feature_funcs)\n",
    "Fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from patch_gnn.graph import (\n",
    "    identity_matrix, \n",
    "    adjacency_matrix, \n",
    "    laplacian_matrix,\n",
    "    to_adjacency_xarray\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjacency tensors\n",
    "\n",
    "Next up, we stack the adjacency tensors together.\n",
    "We are going to use 5 adjacency-like matrices, the 1st-3rd power adjacency matrices,\n",
    "followed by the identity matrix and the graph laplacian matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "adjacency_funcs = []\n",
    "for i in range(3):\n",
    "    adjacency_funcs.append(partial(adjacency_matrix, power=i, name=f\"adjacency_{i}\"))\n",
    "adjacency_funcs.extend(\n",
    "    [\n",
    "        identity_matrix,\n",
    "        laplacian_matrix,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As = stack_adjacency_tensors(graph_patches, funcs=adjacency_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we build the neural network layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "\n",
    "from jax import lax, vmap, jit, grad\n",
    "from jax.experimental import stax\n",
    "\n",
    "from patch_gnn.layers import MessagePassing, GraphAverage, GraphSummation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example model that we might write\n",
    "\n",
    "Firstly, we might want a custom graph embedding.\n",
    "\n",
    "Here, what we do is stack together a message passing layer,\n",
    "followed by Dense-Simgoid transformation,\n",
    "followed by a graph summation op,\n",
    "then another linear projection to 256 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomGraphEmbedding(n_output: int):\n",
    "    \"\"\"Return an embedding of a graph in n_output dimensions.\"\"\"\n",
    "    init_fun, apply_fun = stax.serial(\n",
    "        MessagePassing(),\n",
    "        stax.Dense(2048),\n",
    "        stax.Sigmoid,\n",
    "        GraphSummation(),\n",
    "        stax.Dense(n_output),\n",
    "    )\n",
    "    return init_fun, apply_fun\n",
    "\n",
    "embedding_init_fun, embedding_apply_fun = CustomGraphEmbedding(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegression(num_outputs):\n",
    "    \"\"\"Linear regression layer.\"\"\"\n",
    "    init_fun, apply_fun = stax.serial(\n",
    "        stax.Dense(num_outputs),\n",
    "    )\n",
    "    return init_fun, apply_fun\n",
    "\n",
    "def LogisticRegression(num_outputs):\n",
    "    \"\"\"Logistic regression layer.\"\"\"\n",
    "    init_fun, apply_fun = stax.serial(\n",
    "        stax.Dense(num_outputs),\n",
    "        stax.Softmax,\n",
    "    )\n",
    "    return init_fun, apply_fun\n",
    "\n",
    "model_init_fun, model_apply_fun = stax.serial(\n",
    "    CustomGraphEmbedding(256),\n",
    "    LinearRegression(1),\n",
    ")\n",
    "\n",
    "output_shape, params = model_init_fun(PRNGKey(42), input_shape=(*Fs[0].shape, As[0].shape[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we pass the data through the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = (As, Fs)\n",
    "out = vmap(partial(model_apply_fun, params))(inputs)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = vmap(partial(embedding_apply_fun, params[0]))(inputs)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try some really dumb learning task, like learning random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "\n",
    "outputs = onp.random.normal(size=(len(graph_patches), 1))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try to predict these two numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patch_gnn.training import mseloss\n",
    "\n",
    "dloss = grad(mseloss)\n",
    "mseloss(params, model_apply_fun, inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the loss - it's pretty high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental.optimizers import adam\n",
    "from patch_gnn.training import mseloss\n",
    "from jax import grad\n",
    "\n",
    "dmseloss = grad(mseloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from typing import Tuple\n",
    "\n",
    "init, update, get_params = adam(step_size=1e-3)\n",
    "get_params = jit(get_params)\n",
    "state = init(params)\n",
    "\n",
    "random_training_step = partial(step, dloss_fun=dmseloss, apply_fun=model_apply_fun, update_fun=update, get_params=get_params, inputs=inputs, outputs=outputs)\n",
    "random_training_step = jit(random_training_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "for i in tqdm(range(1000)):\n",
    "    state = random_training_step(i, state, inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_final = get_params(state)\n",
    "mseloss(params_final, model_apply_fun, inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mseloss(params, model_apply_fun, inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = vmap(partial(model_apply_fun, params_final))(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_preds = vmap(partial(model_apply_fun, params))(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(preds.squeeze(), outputs.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(original_preds.squeeze(), outputs.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are the graphs distinguishable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding for first graph, unoptimized params\n",
    "vmap(partial(embedding_apply_fun, params_final[0]))(inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding for second graph, unoptimized params\n",
    "vmap(partial(embedding_apply_fun, params_final[0]))(inputs)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding for first graph, optimized params\n",
    "vmap(partial(embedding_apply_fun, params_final[0]))(inputs)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding for second graph, optimized params\n",
    "vmap(partial(embedding_apply_fun, params_final[0]))(inputs)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.tree_util import tree_map, tree_flatten, tree_multimap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr, unflattener = tree_flatten(params)\n",
    "type(unflattener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_diff(a1, a2):\n",
    "    return a1 - a2\n",
    "\n",
    "tree_map(np.mean, tree_multimap(array_diff, params, params_final)), tree_map(np.std, tree_multimap(array_diff, params, params_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAVEYARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"You've hit the graveyard!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_adj = adjacency_matrix(subG)\n",
    "G_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_adj.shape, F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is message passing in linear algebra form\n",
    "\n",
    "F1 = np.dot(G_adj, F)\n",
    "F1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F2 = np.dot(G_adj, F1)\n",
    "F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F3 = np.dot(G_adj, F2)\n",
    "F3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patch-gnn",
   "language": "python",
   "name": "patch-gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
