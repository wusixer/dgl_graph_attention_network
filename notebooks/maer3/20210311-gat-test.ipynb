{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patch_gnn.data import load_ghesquire\n",
    "import pandas as pd\n",
    "from pyprojroot import here\n",
    "import pickle as pkl\n",
    "from patch_gnn.splitting import train_test_split\n",
    "from jax import random\n",
    "from patch_gnn.seqops import one_hot\n",
    "from patch_gnn.graph import graph_tensors\n",
    "from patch_gnn.models import MPNN, DeepMPNN\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import explained_variance_score as evs\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import pickle as pkl\n",
    "from patch_gnn.graph import met_position\n",
    "\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_ghesquire()\n",
    "\n",
    "graph_pickle_path = here() / \"data/ghesquire_2011/graphs.pkl\"\n",
    "\n",
    "with open(graph_pickle_path, \"rb\") as f:\n",
    "    graphs = pkl.load(f)\n",
    "\n",
    "key = random.PRNGKey(490)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = (\n",
    "    data\n",
    "    .query(\"`accession-sequence` in @graphs.keys()\")\n",
    "    .query(\"ox_fwd_logit < 0.0\")\n",
    "    .join_apply(met_position, \"met_position\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(key, filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph = graph_tensors(train_df, graphs)\n",
    "test_graph = graph_tensors(test_df, graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train_df['ox_fwd_logit'].values\n",
    "test_target = test_df['ox_fwd_logit'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental import stax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(train_graph[0][0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patch_gnn.layers import GraphAttention\n",
    "from jax import vmap\n",
    "from functools import partial\n",
    "\n",
    "init_fun, apply_fun = GraphAttention(n_output_dims=128)\n",
    "\n",
    "output_shape, params = init_fun(key, input_shape=(20, 65, 1))\n",
    "\n",
    "out = vmap(partial(apply_fun, params))(train_graph)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes to self:\n",
    "\n",
    "1. Input shape is always `(-1, n_node_feats)`.\n",
    "2. Always vmap the `apply_fun`!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patch_gnn.layers import GraphSummation\n",
    "model_init_fun, model_apply_fun = stax.serial(\n",
    "    GraphAttention(n_output_dims=128),\n",
    "    GraphSummation(),\n",
    "    stax.Dense(128),\n",
    "    stax.Relu,\n",
    "    stax.Dense(1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_shape, params = model_init_fun(key, input_shape=(20, 65, 1))\n",
    "output = vmap(partial(model_apply_fun, params))(train_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patch_gnn.models import DeepGAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepGAT(node_feature_shape=(20, 65), num_adjacency=1, num_training_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patch_gnn.layers import concatenate_node_features, node_attention\n",
    "\n",
    "attentions, output = vmap(partial(node_attention, model.params[0]))(train_graph)\n",
    "sns.heatmap(attentions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_graph, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = -1\n",
    "preds = model.predict(test_graph, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_target.squeeze(), preds.squeeze())\n",
    "plt.plot([-5, 0], [-5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.loss_history)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = model.predict(train_graph, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_target.squeeze(), train_preds.squeeze())\n",
    "plt.plot([-5, 0], [-5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score as evs, r2_score as r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from jax import jit\n",
    "def learning_curves(model, data, score_func, *, interval: int=20):\n",
    "    X, y = data\n",
    "    scores = []\n",
    "    for i in tqdm(range(len(model.loss_history))[::interval]):\n",
    "        preds = model.predict(X, checkpoint=i)\n",
    "        score = score_func(y.squeeze(), preds.squeeze())\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 5\n",
    "train_score = learning_curves(model, (train_graph, train_target), r2, interval=interval)\n",
    "test_score = learning_curves(model, (test_graph, test_target), r2, interval=interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning curve with epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_score)\n",
    "plt.plot(test_score)\n",
    "plt.xlabel(f\"Training steps divided by {interval}\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.title(\"r2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2(train_target.squeeze(), train_preds.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2(test_target.squeeze(), preds.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore what's learned by GATs\n",
    "\n",
    "Per-graph, what is the attention matrix like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "from patch_gnn.layers import concatenate_node_features, node_attention\n",
    "from jax import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.query(\"ox_fwd_logit > -0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(train_df.index).index(2297)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = train_df.iloc[idx]\n",
    "row[\"ox_fwd_logit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_key = row[\"accession-sequence\"]\n",
    "g_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = graphs[g_key]\n",
    "g.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "aa_props = pd.read_csv(here() / \"data/amino_acid_properties.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(aa_props.index)\n",
    "index.extend([\"Phob\", \"Phil\", \"SASA\", \"N\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(dict(zip(index, np.abs(model.params[0][2])))).sort_values().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "attentions, output = vmap(partial(node_attention, model.params[0]))(train_graph)\n",
    "ax = sns.heatmap(attentions[idx][0:len(g.nodes()), 0:len(g.nodes())], cmap=\"viridis\")\n",
    "ax.set_xticklabels(list(g.nodes()), rotation = 90)\n",
    "ax.set_yticklabels(list(g.nodes()), rotation = 0)\n",
    "attentions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vertical numbers are not all identical. Keep that in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "nx.draw(g, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAVEYARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patch_gnn.layers import normalize_if_nonzero\n",
    "from jax import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_if_nonzero(p_vect=np.zeros(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0.1, 0.5, 0.0])\n",
    "normalize_if_nonzero(p_vect=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(p):\n",
    "    p = normalize_if_nonzero(p)\n",
    "    return np.sum(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(np.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = grad(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df(np.zeros(3)),  df(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patch-gnn",
   "language": "python",
   "name": "patch-gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
