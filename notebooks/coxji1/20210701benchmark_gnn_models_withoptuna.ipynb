{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script is just to show Optuna works on graph models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "from patch_gnn.data import load_ghesquire\n",
    "import pandas as pd\n",
    "from pyprojroot import here\n",
    "import pickle as pkl\n",
    "from patch_gnn.splitting import train_test_split\n",
    "from jax import random\n",
    "from patch_gnn.seqops import one_hot\n",
    "from patch_gnn.unirep import unirep_reps\n",
    "from patch_gnn.graph import graph_tensors\n",
    "from patch_gnn.models import MPNN, DeepMPNN, DeepGAT\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import explained_variance_score as evs\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import pickle as pkl\n",
    "from patch_gnn.graph import met_position\n",
    "import seaborn as sns\n",
    "from patch_gnn.tune import evotune_mpnn_class, evotune_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and its asscociated graphs\n",
    "##### Data is the raw data, while its associated graph,pkl has only sasa and fluc features. Loading its associated garph is necessary given graphs.pkl contains accession-sequence identifier needed to subset raw data for analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_ghesquire()\n",
    "\n",
    "graph_pickle_path = here() / \"data/ghesquire_2011/graphs.pkl\"\n",
    "processed_data_path = here() / \"data/ghesquire_2011/processed_data.pkl\"\n",
    "\n",
    "with open(graph_pickle_path, \"rb\") as f:\n",
    "    graphs = pkl.load(f)\n",
    "\n",
    "# the cleaned data has everything processed and ready to be used for deep learning\n",
    "with open(processed_data_path, \"rb\") as f:\n",
    "    processed_data = pkl.load(f)\n",
    "    \n",
    "key = random.PRNGKey(490)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### An example of what metadata looks like for a node in a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chain_id': '',\n",
       " 'residue_number': 312,\n",
       " 'residue_name': 'VAL',\n",
       " 'x_coord': 8.135,\n",
       " 'y_coord': 35.62,\n",
       " 'z_coord': 81.989,\n",
       " 'features': None,\n",
       " 'log_Phob/A^2': 2.9317269435780786,\n",
       " 'log_Phil/A^2': 1.0784095813505903,\n",
       " 'log_SASA/A^2': 3.077312260546414,\n",
       " 'log_N(overl)': 6.159095388491933,\n",
       " 'anm': 0.408609008319972,\n",
       " 'nma': 0.119027078014224}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs['P40121-VSDATGQMNLTK'].nodes(data=True)['312VAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q8IXH7-MFTSMDPPPVELIR\n",
      "P00492-VFIPHGLIMDR\n",
      "O75874-LIDDMVAQAMK\n",
      "P67936-MEIQEMQLK\n",
      "the filtered graphs has 359 graphs\n"
     ]
    }
   ],
   "source": [
    "# select the graphs that only exist in fitered dataset\n",
    "# one cannot directly loop through the dict keys, and delete certain ones b/c it is changing \n",
    "graphs_to_remove = []\n",
    "for graph_key in graphs.keys():\n",
    "    if graph_key not in processed_data[\"accession-sequence\"].tolist():\n",
    "        print(graph_key)\n",
    "        graphs_to_remove.append(graph_key)\n",
    "for graph_key in graphs_to_remove:\n",
    "    graphs.pop(graph_key)\n",
    "print(f\"the filtered graphs has {len(list(graphs.values()))} graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split data in to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((251, 18), (108, 18))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(key, processed_data) # 70% training, 30% testing\n",
    "(train_df.shape), (test_df.shape) #359 total raw data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this the num of train + test samples  = total graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_y_eq_x(ax):\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "\n",
    "    minval = min(xmin, ymin)\n",
    "    maxval = max(xmax, ymax)\n",
    "\n",
    "    ax.plot([minval, maxval], [minval, maxval])\n",
    "\n",
    "def plot_performance(\n",
    "    model,\n",
    "    trainX, trainY, testX, testY,\n",
    "    model_name: str,\n",
    "    ev_func,\n",
    "    checkpoint: int = None,\n",
    "):\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(10, 5), nrows=1, ncols=2, sharex=True, sharey=True,\n",
    "    )\n",
    "    # evaluate model is MPNN class, b/c other deep learning models inhert from this class, they are all under this class\n",
    "    if isinstance(model, MPNN):\n",
    "        train_preds = model.predict(trainX, checkpoint=checkpoint)\n",
    "    else:\n",
    "        train_preds = model.predict(trainX)\n",
    "    ax[0].scatter(trainY, train_preds.squeeze())\n",
    "    ax[0].set_title(f\"Model: {model_name}, Training Perf: {ev_func(trainY, train_preds.squeeze()):.3f}\")\n",
    "    plot_y_eq_x(ax[0])\n",
    "\n",
    "    if isinstance(model, MPNN):\n",
    "        test_preds = model.predict(testX, checkpoint=checkpoint)\n",
    "    else:\n",
    "        test_preds = model.predict(testX)\n",
    "    ax[1].scatter(testY, test_preds.squeeze())\n",
    "    ax[1].set_title(f\"Model: {model_name}, Testing Perf: {ev_func(testY, test_preds.squeeze()):.3f}\")\n",
    "    plot_y_eq_x(ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning related model of interests\n",
    "- Graph based models\n",
    "    - Massage passing neural network (MPNN)\n",
    "    - Deep message passing neural network (DMPNN)\n",
    "    - Deep graph attention neural network (DeepGAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 567) (108, 567)\n",
      "(251, 1900) (108, 1900)\n",
      "(251, 20, 20, 1) (251, 20, 67)\n"
     ]
    }
   ],
   "source": [
    "train_graph = graph_tensors(train_df, graphs) # use graph + sasa features + fluc features\n",
    "test_graph = graph_tensors(test_df, graphs)\n",
    "\n",
    "# get an idea of the output dim of graph_tensors\n",
    "adjs, feats = graph_tensors(train_df, graphs)\n",
    "print(adjs.shape, feats.shape) # adjs: (n_sample, n_node, n_node, 1), feats: (n_sample, n_node, n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load target value\n",
    "train_target = train_df['ox_fwd_logit'].values\n",
    "test_target = test_df['ox_fwd_logit'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training for non-linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_training_steps = 5000\n",
    "node_feature_shape = (20,67)\n",
    "num_adjacency =1\n",
    "num_training_steps = 5 # put it here and later it would be overwritten by optuna\n",
    "deep_models = {\n",
    "    \"mpnn\": MPNN(\n",
    "        node_feature_shape=node_feature_shape,# (num_nodes is number of unique animo acid, num_feats from data/amino_acid_properties.csv + 4 sasa_dfs features +2 fluc features )\n",
    "        num_adjacency=num_adjacency,\n",
    "        num_training_steps=num_training_steps\n",
    "    ),\n",
    "    \"deep_mpnn\": DeepMPNN(\n",
    "        node_feature_shape=node_feature_shape,\n",
    "        num_adjacency=num_adjacency,\n",
    "        num_training_steps=num_training_steps\n",
    "    ),\n",
    "    \"deep_gat\": DeepGAT(\n",
    "        node_feature_shape = node_feature_shape,\n",
    "        num_adjacency = num_adjacency,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deep models hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_steps_kwargs = {\n",
    "    \"name\": \"num_training_steps\",\n",
    "    \"low\": 4,\n",
    "    \"high\": 500,\n",
    "    \"log\": True,\n",
    "}\n",
    "#num_training_steps_kwargs={}\n",
    "optimizer_step_size_kwargs={\n",
    "    \"name\" : \"optimizer_step_size\",# this key value pair is required as is\n",
    "    \"low\" : 1e-5, # one can change the value\n",
    "    \"high\" : 1e-2, # one can change the value\n",
    "} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-06 16:02:21,156]\u001b[0m A new study created in memory with name: no-name-75c19d1d-4c13-4793-9da4-5ddaa23ac0dd\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The params that were optimized is {'num_training_steps': 4, 'optimizer_step_size': 0.005263207454577327}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70dcf2b6dabc40b1a2b35938a76bc492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-06 16:02:22,593]\u001b[0m Trial 0 finished with value: 10.531705856323242 and parameters: {'num_training_steps': 4, 'optimizer_step_size': 0.005263207454577327}. Best is trial 0 with value: 10.531705856323242.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_training_steps': 4, 'optimizer_step_size': 0.005263207454577327}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evotune_mpnn_class(deep_models['mpnn'], train_graph, train_target, num_training_steps_kwargs, optimizer_step_size_kwargs, n_trials = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start training all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for deep_model in deep_models.keys():\n",
    "    print(f\"training {deep_model} model now\")\n",
    "    deep_models[deep_model].fit(train_graph, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_models[\"mpnn\"].loss_history[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train gat model more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_models[\"deep_gat\"].fit(train_graph, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which checkpoint for NN models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(deep_models[\"mpnn\"].loss_history)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(deep_models[\"deep_mpnn\"].loss_history)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(deep_models[\"deep_gat\"].loss_history)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint at 400 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = 400\n",
    "plot_performance(deep_models[\"mpnn\"], train_graph, train_target, test_graph, test_target, f'MPNN, evs, {checkpoint}', evs, checkpoint=checkpoint)\n",
    "plot_performance(deep_models[\"deep_mpnn\"], train_graph, train_target, test_graph, test_target, f'Deep MPNN, evs, {checkpoint}', evs, checkpoint=checkpoint)\n",
    "plot_performance(deep_models[\"deep_gat\"], train_graph, train_target, test_graph, test_target, f'Deep MPNN, evs, {checkpoint}', evs, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint at 600 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = 600\n",
    "plot_performance(deep_models[\"mpnn\"], train_graph, train_target, test_graph, test_target, f'MPNN, evs, {checkpoint}', evs, checkpoint=checkpoint)\n",
    "plot_performance(deep_models[\"deep_mpnn\"], train_graph, train_target, test_graph, test_target, f'Deep MPNN, evs, {checkpoint}', evs, checkpoint=checkpoint)\n",
    "plot_performance(deep_models[\"deep_gat\"], train_graph, train_target, test_graph, test_target, f'Deep MPNN, evs, {checkpoint}', evs, checkpoint=checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(deep_models[\"deep_gat\"], MPNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = 1000\n",
    "plot_performance(deep_models[\"mpnn\"], train_graph, train_target, test_graph, test_target, f'MPNN, evs, {checkpoint}', evs, checkpoint=checkpoint)\n",
    "plot_performance(deep_models[\"deep_mpnn\"], train_graph, train_target, test_graph, test_target, f'Deep MPNN, evs, {checkpoint}', evs, checkpoint=checkpoint)\n",
    "plot_performance(deep_models[\"deep_gat\"], train_graph, train_target, test_graph, test_target, f'Deep MPNN, evs, {checkpoint}', evs, checkpoint=checkpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint at Final steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(deep_models[\"mpnn\"], train_graph, train_target, test_graph, test_target, f'MPNN, evs', evs, checkpoint=-1)\n",
    "plot_performance(deep_models[\"deep_mpnn\"], train_graph, train_target, test_graph, test_target, f'Deep MPNN, evs',  evs, checkpoint=-1)\n",
    "plot_performance(deep_models[\"deep_gat\"], train_graph, train_target, test_graph, test_target, f'Deep GAT, evs', evs, checkpoint=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patch-gnn",
   "language": "python",
   "name": "patch-gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
